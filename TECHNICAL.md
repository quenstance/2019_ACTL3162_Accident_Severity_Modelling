## **Technical Methodology: Accident Severity Modelling & Ruin Probability**

This document provides a detailed technical overview of the methodologies and mathematical underpinnings of the project, conducted using the **R programming language**.

---

### Task 1: Accident Severity Distribution

The primary objective of this task was to identify the most suitable continuous distribution for accident severity from a dataset of motor insurance claims. The core of the methodology revolved around **Maximum Likelihood Estimation (MLE)** for truncated data.

1.  **Data Preparation and Exploration**: The initial step involved calculating the total loss for each claim by summing the basic excess, elected excess, and claims paid. The data was loaded from `LossData.csv`, and summary statistics (e.g., standard deviation, kurtosis, skewness) were calculated. Initial distribution insights were gained from a Cullen and Frey skewness-kurtosis plot generated by the `descdist()` function from the `fitdistrplus` package.

2.  **Truncated Likelihood Function**: To account for the policy excess, a truncated likelihood function was maximized to estimate the parameters for various continuous distributions, including Gamma, Lognormal, and Burr. The function is defined as:

    $$L(\theta;x)=\prod_{i=1}^{n}\frac{f(x_{i};\theta)}{1-F(t_{i};\theta)}$$

    Where:
    * $f(x_{i};\theta)$ is the **probability density function (PDF)** of the selected distribution (e.g., Lognormal, Pareto, or Gamma) evaluated at the total loss $x_i$.
    * $F(t_{i};\theta)$ is the corresponding **cumulative distribution function (CDF)** evaluated at the truncation point $t_i$.
    * $x_i$ represents the total loss for a given claim.
    * $t_i$ is the truncation point, which corresponds to the excess for each policy, below which claims are not observed.

    The maximization of the log-likelihood function was computationally performed using the `fitdist()` function from the `fitdistrplus` package. For more complex distributions like the Burr, initial parameter guesses were provided to assist in convergence.

3.  **Model Validation and Selection**: A rigorous, multi-faceted approach was used to determine the best-fitting distribution.
    * **Graphical Methods**: Visual assessments were made using the `denscomp()`, `cdfcomp()`, `qqcomp()`, and `ppcomp()` functions from the `fitdistrplus` package to compare the empirical and theoretical distributions.
    * **Statistical Goodness-of-Fit Tests**: The model's fit was formally evaluated using the `gofstat()` function, which provides metrics for the **Kolmogorov-Smirnov (KS)**, **Cramér-von Mises (CvM)**, and **Anderson-Darling (AD)** tests. The AD test, which places greater weight on the tails of the distribution, was particularly crucial given its relevance to insurance claims.
    * **Information Criteria**: The **Akaike Information Criterion (AIC)** and **Bayesian Information Criterion (BIC)** were used for penalized model selection, balancing model fit with complexity. Since all models under consideration had two parameters, a direct comparison of the maximized log-likelihoods was sufficient.

---

### Task 2: Ruin Theory

This task explored the financial stability of an insurer through two primary actuarial techniques: continuous-time ruin theory and discrete-time aggregation.

1.  **Continuous-Time Ruin and the Adjustment Coefficient**: The analysis focused on solving for the **adjustment coefficient, R**, within the **Cramér-Lundberg model**. This coefficient is the positive root of the following equation, known as the Cramér-Lundberg equation:

    $$\psi(c_0)=e^{-R c_0}$$

    Where $\psi$ is the ultimate ruin probability and $c_0$ is the initial surplus. The adjustment coefficient is a critical measure of an insurer's solvency, as it quantifies the rate at which the probability of ruin decreases as the initial surplus increases. The project solved for R under three distinct scenarios using the `uniroot.all()` and `uniroot()` functions in R, after symbolically finding the moment generating function (MGF) using the `rSymPy` package.

    * **Without Reinsurance**: The equation was defined and solved for R using `uniroot.all(eqR.a, c(0, 1))`.
    * **Proportional Reinsurance**: The modified MGF was used to define the equation `eqR.b` for proportional reinsurance, with the optimal adjustment coefficient found using `uniroot.all()` for a specific proportion parameter.
    * **Non-Proportional Reinsurance (Excess of Loss)**: The new MGF was derived from the truncated claims data, and the corresponding equation `eqR.c` was solved for R using `uniroot.all()`. The Lundberg lower and upper bounds were also calculated using the derived adjustment coefficient.

2.  **Discrete-Time Aggregation via Panjer Recursion**: The **Panjer recursion** algorithm was implemented to compute the **probability mass function (PMF)** and **cumulative distribution function (CDF)** of aggregate losses. This method is highly efficient for finding the distribution of a sum of independent and identically distributed random variables, particularly when the frequency distribution belongs to the $(a,b,0)$ class of distributions. The numerical output from this method was then compared against the true values to validate the accuracy and computational efficiency of the approximation.